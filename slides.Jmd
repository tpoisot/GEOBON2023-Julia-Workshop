---
title: Interpretable ML for biodiversity
subtitle: An introduction using species distribution models
author: Timothée Poisot
institute: Université de Montréal
date: \today
weave_options:
    doctype: pandoc
    echo: false
    term: false
    cache: true
---

```julia
using SpeciesDistributionToolkit
using CairoMakie
using Statistics
set_theme!()
CairoMakie.activate!(; type = "png")
update_theme!(;
    backgroundcolor = :transparent,
    fontsize = 15,
    Figure = (; backgroundcolor = :transparent),
    Axis = (
        backgroundcolor = :transparent,
    ),
    CairoMakie = (; px_per_unit = 3),
)
```

## Main goals

1. How do we produce a model?
2. How do we convey that it works?
3. How do we talk about how it makes predictions?
4. How do we use it to guide actions?

## The steps

1. Get data about species occurrences
2. Build a classifier and make it as good as we can
3. Measure its performance
4. Explain some predictions
5. Generate counterfactual explanations
6. Briefly discuss ensemble models

## But why...

... think of SDM as a ML problem?
: Because they are! We want to learn a predictive algorithm from data

... the focus on explainability?
: We cannot ask people to *trust* - we must *convince* and *explain*

# Problem statement

## The problem in ecological terms

We have information about a species

## The problem in other words

We have a series of observations $y \in \mathbb{B}$, and predictors variables $\mathbf{X} \in \mathbb{R}$

We want to find an algorithm $f(\mathbf{x}) = \hat y$ that results in the distance between $\hat y$ and $y$ being *small*

## Setting up the data for our example

The predictor data will come from CHELSA2 - we will start with the 19 BioClim variables

```julia
CHE = SpeciesDistributionToolkit.gadm("CHE");
provider = RasterData(CHELSA2, BioClim)
layers = [
    SDMLayer(
        provider;
        layer = x,
        left = 0.0,
        right = 20.0,
        bottom = 35.0,
        top = 55.0,
    ) for x in 1:19
];
layers = [trim(mask!(layer, CHE)) for layer in layers];
layers = map(l -> convert(SDMLayer{Float32}, l), layers);
```


We will use data on observations of *Turdus torquatus* in Switzerland, downloaded from the copy of the eBird dataset on GBIF


```julia
ouzel = taxon("Turdus torquatus")
presences = occurrences(
    ouzel,
    first(layers),
    "occurrenceStatus" => "PRESENT",
    "limit" => 300,
    "datasetKey" => "4fa7b334-ce0d-4e88-aaae-2e0c138d049e",
)
while length(presences) < count(presences)
    occurrences!(presences)
end
```

## The observation data

```julia
f = Figure(; size=(600, 280))
ax = Axis(f[1,1], aspect=DataAspect())
poly!(ax, CHE.geometry[1], color=:lightgrey)
scatter!(ax, mask(presences, CHE), color=:black)
lines!(ax, CHE.geometry[1]; color = :black)
hidedecorations!(ax)
hidespines!(ax)
current_figure()
```

## Problem!

We want $\hat y \in \mathbb{B}$, and so far we are missing \alert{negative values}

## Solution!

pseudo-absences

what are the assumptions we make

```julia
presencelayer = zeros(first(layers), Bool)
for occ in mask(presences, CHE)
    presencelayer[occ.longitude, occ.latitude] = true
end

background = pseudoabsencemask(DistanceToEvent, presencelayer)
bgpoints = backgroundpoints(nodata(background, d -> d < 4), 2sum(presencelayer))
```

## The (inflated) observation data

```julia
f = Figure(; size=(600, 280))
ax = Axis(f[1,1], aspect=DataAspect())
poly!(ax, CHE.geometry[1], color=:lightgrey)
scatter!(ax, presencelayer; color = :black)
scatter!(ax, bgpoints; color = :red, markersize = 4)
lines!(ax, CHE.geometry[1]; color = :black)
hidedecorations!(ax)
hidespines!(ax)
current_figure()
```

# Training the model

## The Naive Bayes Classifier

$$P(+|x) = \frac{P(+)}{P(x)}P(x|+)$$

$$\hat y = \text{argmax}_j \, P(\mathbf{c}_j)\prod_i P(\mathbf{x}_i|\mathbf{c}_j)$$

$$P(x|+) = \text{pdf}(x, \mathcal{N}(\mu_+, \sigma_+))$$

## Setup

```julia
sdm = SDM(MultivariateTransform{PCA}, NaiveBayes, layers, presencelayer, bgpoints)
```

## Cross-validation

Can we train the model

assumes parallel universes with slightly less data

is the model good?

## Null classifiers

coin flip

no skill

constant

## Cross-validation strategy

k-fold

validation / training / testing

```julia
folds = kfold(sdm);
cv = crossvalidate(sdm, folds; threshold = false);
mean(mcc.(cv.validation))
```

## What to do if the model is trainable?

train it!

re-use the full dataset

```julia
train!(sdm; threshold=false)
prd = predict(sdm, layers; threshold = false)
current_range = predict(sdm, layers)
```

## Initial prediction

```julia
f = Figure(; size = (600, 280))
ax = Axis(f[1, 1]; aspect = DataAspect(), title = "Prediction")
hm = heatmap!(ax, prd; colormap = :linear_worb_100_25_c53_n256, colorrange = (0, 1))
contour!(ax, predict(sdm, layers); color = :black, linewidth = 0.5)
Colorbar(f[1, 2], hm)
lines!(ax, CHE.geometry[1]; color = :black)
hidedecorations!(ax)
hidespines!(ax)
current_figure()
```

## Can we improve on this model?

variable selection

```julia
forwardselection!(sdm, folds)
```

data transformation

hyper-parameters tuning

will focus on the later (same process for the two above)

## Moving theshold classification

p plus > p minus means threshold is 0.5

is it?

how do we check this

```julia
THR = LinRange(0.0, 1.0, 200)
cv = [crossvalidate(sdm, folds; thr=thr) for thr in THR]
bst = last(findmax([mean(mcc.(c.training)) for c in cv]))
```

## Learning curve for the threshold

```julia
lines(THR, [mean(mcc.(c.validation)) for c in cv])
lines!(THR, [mean(mcc.(c.training)) for c in cv])
scatter!([THR[bst]], [mean(mcc.(cv[bst].validation))])
current_figure()
```

## ROC

```julia
lines([mean(fpr.(c.validation)) for c in cv], [mean(tpr.(c.validation)) for c in cv])
scatter!([mean(fpr.(cv[bst].validation))], [mean(tpr.(cv[bst].validation))])
current_figure()
```

## PR

```julia
lines([mean(ppv.(c.validation)) for c in cv], [mean(tpr.(c.validation)) for c in cv])
scatter!([mean(ppv.(cv[bst].validation))], [mean(tpr.(cv[bst].validation))])
current_figure()
```

## Revisting the model performance

```julia
cv = crossvalidate(sdm, folds; threshold = true)
mean(npv.(cv.validation))
npv(noskill(sdm))
```

```julia
train!(sdm)
prd = predict(sdm, layers; threshold = false)
current_range = predict(sdm, layers)
```

## Updated prediction

```julia
f = Figure(; size = (600, 280))
ax = Axis(f[1, 1]; aspect = DataAspect())
hm = heatmap!(ax, prd; colormap = :linear_worb_100_25_c53_n256, colorrange = (0, 1))
contour!(ax, predict(sdm, layers); color = :black, linewidth = 0.5)
Colorbar(f[1, 2], hm)
lines!(ax, CHE.geometry[1]; color = :black)
hidedecorations!(ax)
hidespines!(ax)
current_figure()
```

## Variable importance

```julia
variableimportance(sdm, folds)
```

# But why?

## Intro explainable

## An ecology tool: partial response curves

## Example with temperature

```julia
x, y = partialresponse(sdm, 1; threshold=false)
scatter(x, y)
```

## Example with two variables

```julia
x, y, z = partialresponse(sdm, 1, 10; threshold=false)
heatmap(x, y, z, colormap=:linear_worb_100_25_c53_n256, colorrange=(0,1))
```

## On a map

```julia
partial_temp = partialresponse(sdm, layers, 1; threshold=false)
heatmap(partial_temp)
```

## On a map v2

```julia
partial_temp = partialresponse(sdm, layers, 1; threshold=true)
heatmap(partial_temp)
```

## Inflated response curve

what issue they solve

## Example

```julia
f = Figure()
ax = Axis(f[1,1])
for i in 1:300
    lines!(partialresponse(sdm, 1; inflated=true, threshold=false)..., color=:lightgrey, alpha=0.5)
end
lines!(partialresponse(sdm, 1; inflated=false, threshold=false)..., color=:black)
current_figure()
```

## Limitations

not accounting for other values of variables at observation

## Shapley

## Example

```julia
explain(sdm, 1; threshold=false)
```

## Response curves revisited

```julia
scatter(features(sdm, 1), explain(sdm, 1; threshold=false))
```

## On a map

```julia
shapley_temp = explain(sdm, layers, 1; threshold=false)
heatmap(shapley_temp, colorrange=(-0.1, 0.1), colormap=:diverging_bwg_20_95_c41_n256)
```

## Variable importance revisited

with shapley

## Most important predictor

mosaic map

# What if?

## Intro to counterfactuals

what they are

# Ensemble models

# Conclusions