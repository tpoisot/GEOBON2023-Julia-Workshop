---
title: "Building an interpretable SDM from scratch"
subtitle: "using Julia 1.9"
author:
    name: "Timothée Poisot"
    email: timothee.poisot@umontreal.ca
institute: "Université de Montréal"
title-slide-attributes: 
  data-background-image: https://cdn.pixabay.com/photo/2017/03/29/11/29/nepal-2184940_960_720.jpg
  data-background-opacity: "0.15"
bibliography: references.bib
csl: https://www.zotero.org/styles/ecology-letters
---

## Overview

-   Build a *simple* classifier to predict the distribution of a species

-   Use this as an opportunity to talk about interpretable ML

-   Discuss which biases are appropriate in a predictive model

::: footer
CC BY 4.0 - Timothée Poisot
:::

------------------------------------------------------------------------

::: r-fit-text
We care a lot about the

**process**

and only a little about the

**product**
:::

------------------------------------------------------------------------

## Raccoons!

-   Relatable (bag under eyes, love naps, out of shape)

-   High volume of data

-   Species of concern for zoonotic diseases

-   Where can we find them in/around Québec?

::: footer
See also @higino2021 for more quality 🦝 content
:::

## Do try this at home!

💻 + 📔 + 🗺️ at `https://github.com/tpoisot/InterpretableSDMWithJulia/`

```{julia}
#| label: Include the packages we need
#| echo: true
#| output: false
include(joinpath("code", "pkg.jl")); # Dependencies
include(joinpath("code", "nbc.jl")); # Naive Bayes Classifier
include(joinpath("code", "bioclim.jl")); # BioClim model
include(joinpath("code", "confusion.jl")); # Confusion matrix utilities
include(joinpath("code", "splitters.jl")); # Cross-validation
include(joinpath("code", "crossvalidate.jl")); # Cross-validation
include(joinpath("code", "variableselection.jl")); # Variable selection
include(joinpath("code", "shapley.jl")); # Shapley values
include(joinpath("code", "palettes.jl")); # Color palettes
```

## Species occurrences

```{julia}
#| label: Get the species from the BFRO reports
#| eval: true
#| echo: true
#| output: false
sightings = CSV.File("occurrences.csv")
occ = [
    (record.longitude, record.latitude)
    for record in sightings
    if record.classification == "Class A"
]
filter!(r -> -90 <= r[2] <= 90, occ)
filter!(r -> -180 <= r[1] <= 180, occ)
boundingbox = (
    left = minimum(first.(occ)),
    right = maximum(first.(occ)),
    bottom = minimum(last.(occ)),
    top = maximum(last.(occ)),
)
```

## Bioclimatic data

We collect BioClim data from CHELSA v1, using `SpeciesDistributionToolkit`

```{julia}
#| label: Download the BioClim data from WorldClim2
#| eval: true
#| echo: true
#| output: false
provider = RasterData(WorldClim2, BioClim)
opts = (; resolution=5.0)
temperature = SimpleSDMPredictor(provider, layer=1; opts..., boundingbox...)
```

::: footer
BioClim data from @karger2020; see @dansereau2021 for more about the packages
:::

## Where are we so far?

```{julia}
#| echo: false
fig = Figure(; resolution=(900, 500))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, temperature, colormap=cgrad(iridescent))
Colorbar(fig[1,2], hm; tellheight=false)
scatter!(ax, occ; color=:black, marker=:cross, markersize=5)
current_figure()
```

## Spatial thinning

We limit the occurrences to one per grid cell, assigned to the center of the grid cell

```{julia}
#| label: Make the layer for presences
#| echo: true
#| eval: true
#| output: false
presence_layer = similar(temperature, Bool)
for i in axes(occ, 1)
    if ~isnothing(presence_layer[occ[i]...])
        presence_layer[occ[i]...] = true
    end
end
```

## Background points generation

We generate background points proportionally to the distance away from observations, with a 10km buffer around each point with no background point allowed:

```{julia}
#| label: Make the pseudo-absence buffer
#| eval: true
#| echo: true
#| output: false
possible_background = pseudoabsencemask(DistanceToEvent, presence_layer)
```

And then we sample three pseudo-absence for each occurrence:

```{julia}
#| label: Make the absence layer
#| echo: true
#| eval: true
#| output: false
absence_layer = backgroundpoints(
    (x -> x^1.01).(possible_background), 
    3sum(presence_layer);
    replace=false
)
```

::: footer
See @barbet-massin2012 for more on background points
:::

## Background points cleaning

We can remove all of the information that is neither a presence nor a pseudo-absence

```{julia}
#| label: Pseudo-absence/presence remove
#| output: false
#| echo: true
replace!(absence_layer, false => nothing)
replace!(presence_layer, false => nothing)
```

## Data overview

```{julia}
heatmap!(possible_background; colormap = cgrad([:transparent, :white]; alpha = 0.3))
current_figure()
```

```{julia}
#| label: Save the stack of layers
#| echo: false
#| output: false
#| eval: true
predictors = [
    SimpleSDMPredictor(provider; layer = l, opts..., boundingbox...)
    for l in layers(provider)
]
```

## Preparing the responses and variables

```{julia}
#| label: Assemble y and X
#| echo: true
#| output: false
Xpresence = hcat([bioclim_var[keys(presence_layer)] for bioclim_var in predictors]...)
ypresence = fill(true, length(presence_layer))
Xabsence = hcat([bioclim_var[keys(absence_layer)] for bioclim_var in predictors]...)
yabsence = fill(false, length(absence_layer))
X = vcat(Xpresence, Xabsence)
y = vcat(ypresence, yabsence)
```

```{julia}
#| output: false
#| echo: false
#| eval: true
bclay = layers(RasterData(WorldClim2, BioClim))
bcdes = layerdescriptions(RasterData(WorldClim2, BioClim))
presences = Tuple.(keys(presence_layer))
absences = Tuple.(keys(absence_layer))
variables = [(bc, bcdes[bc]) for bc in bclay]
```

## The model -- Naive Bayes Classifier

Prediction:

$$
P(+|x) = \frac{P(+)}{P(x)}P(x|+)
$$

Decision rule:

$$
\hat y = \text{argmax}_j \, P(\mathbf{c}_j)\prod_i P(\mathbf{x}_i|\mathbf{c}_j)
$$

::: footer
With $n$ instances and $f$ features, NBC trains *and* predicts in $\mathcal{O}(n\times f)$
:::

## The model -- Naive Bayes Classifier

Assumption of Gaussian distributions:

$$
P(x|+) = \text{pdf}(x, \mathcal{N}(\mu_+, \sigma_+))
$$

## Cross-validation

We keep an **unseen** *testing* set -- this will be used at the very end to report expected model performance

```{julia}
#| label: Testing set
#| echo: true
#| output: false
idx, tidx = holdout(y, X; permute=true)
```

For *validation*, we will run k-folds

```{julia}
#| label: k-folds
#| echo: true
#| output: false
ty, tX = y[idx], X[idx,:]
folds = kfold(ty, tX; k=10, permute=true)
k = length(folds)
```

::: footer
See @valavi2018 for more on cross-validation
:::

## A note on cross-validation

All models share the same folds

:   we can compare the validation performance across experiments to select the best model

Model performance can be compared

:   we average the relevant summary statistics over each validation set

Testing set is *only* for future evaluation

:   we can only use it once and report the expected performance *of the best model*

## Baseline performance

We need to get a sense of how difficult the classification problem is:

```{julia}
#| echo: true
#| output: false
N_v0 = crossvalidate(naivebayes, ty, tX, folds)
B_v0 = crossvalidate(bioclim, ty, tX, folds, eps())
```

This uses an un-tuned model with all variables and reports the average over all validation sets. In addition, we will always use the BioClim model as a comparison.

## Measures on the confusion matrix {.smaller}

|     | BioClim | NBC                                   |
|-----|----|---------------------------------------|
| FPR | `{julia} sm(fpr, B_v0)` | `{julia} sm(fpr, N_v0)` |
| FNR | `{julia} sm(fnr, B_v0)` | `{julia} sm(fnr, N_v0)` |
| TPR | `{julia} sm(tpr, B_v0)` | `{julia} sm(tpr, N_v0)` |
| TNR | `{julia} sm(tnr, B_v0)` | `{julia} sm(tnr, N_v0)` |
| TSS | `{julia} sm(trueskill, B_v0)` | `{julia} sm(trueskill, N_v0)` |
| MCC | `{julia} sm(mcc, B_v0)` | `{julia} sm(mcc, N_v0)` |

::: footer
It's a good idea to check the values for the training sets too...
:::

## Variable selection

We add variables one at a time, until the Matthew's Correlation Coefficient stops increasing -- we keep annual temperature, isothermality, mean diurnal range, and annual precipitation

```{julia}
#| echo: true
#| output: false
available_variables = forwardselection(ty, tX, folds, naivebayes, mcc)
```

This method identifies `{julia} length(available_variables)` variables, some of which are:

1.  `{julia} variables[available_variables[1]][2]`

2.  `{julia} variables[available_variables[2]][2]`

3.  `{julia} variables[available_variables[3]][2]`

## Discuss - can we force variable selection?

-   constrained variable selection

-   VIF + variable selection

-   PCA?

## Model with variable selection

```{julia}
#| echo: true
#| output: false
N_v1 = crossvalidate(naivebayes, ty, tX[:,available_variables], folds)
B_v1 = crossvalidate(bioclim, ty, tX[:,available_variables], folds, eps())
```

## Measures on the confusion matrix {.smaller}

|     | BioClim | NBC  | BioClim (v.s.) | NBC (v.s.)  |
|-----|----|-----------|----|-----------|
| FPR | `{julia} sm(fpr, B_v0)` | `{julia} sm(fpr, N_v0)` | `{julia} sm(fpr, B_v1)` | `{julia} sm(fpr, N_v1)` |
| FNR | `{julia} sm(fnr, B_v0)` | `{julia} sm(fnr, N_v0)` | `{julia} sm(fnr, B_v1)` | `{julia} sm(fnr, N_v1)` |
| TPR | `{julia} sm(tpr, B_v0)` | `{julia} sm(tpr, N_v0)` | `{julia} sm(tpr, B_v1)` | `{julia} sm(tpr, N_v1)` |
| TNR | `{julia} sm(tnr, B_v0)` | `{julia} sm(tnr, N_v0)` | `{julia} sm(tnr, B_v1)` | `{julia} sm(tnr, N_v1)` |
| TSS | `{julia} sm(trueskill, B_v0)` | `{julia} sm(trueskill, N_v0)` | `{julia} sm(trueskill, B_v1)` | `{julia} sm(trueskill, N_v1)` |
| MCC | `{julia} sm(mcc, B_v0)` | `{julia} sm(mcc, N_v0)` | `{julia} sm(mcc, B_v1)` | `{julia} sm(mcc, N_v1)` |

## How do we make the model better?

The NBC is a *probabilistic classifier* returning $P(+|\mathbf{x})$

The *decision rule* is to assign a presence when $P(\cdot) > 0.5$

But $P(\cdot) > \tau$ is a far more general approach, and we can use learning curves to identify $\tau$

## Thresholding the model

```{julia}
#| echo: true
#| output: false
thr = LinRange(0.0, 1.0, 150)
T = hcat([crossvalidate(naivebayes, ty, tX[:,available_variables], folds, t) for t in thr]...)
```

## But how do we pick the threshold?

```{julia}
#| echo: false
fig = Figure(; resolution=(900, 450))

ax_mcc = Axis(fig[1,1], xlabel="Threshold", ylabel="MCC")
ax_tss = Axis(fig[2,1], xlabel="Threshold", ylabel="TSS")

scores = mcc.(T)
σ = vec(std(scores; dims=1))
μ = vec(mean(scores; dims=1))
band!(ax_mcc, thr, μ-σ, μ+σ, color=(:lightgrey, 0.4))
lines!(ax_mcc, thr, μ, color=:black, linewidth=2)

mmax, m = findmax(μ)
scatter!(ax_mcc, thr[m], mmax, color=(:black, 0.5), markersize=20)

scores = trueskill.(T)
σ = vec(std(scores; dims=1))
μ = vec(mean(scores; dims=1))
band!(ax_tss, thr, μ-σ, μ+σ, color=(:lightgrey, 0.4))
lines!(ax_tss, thr, μ, color=:black, linewidth=2)

xlims!(ax_mcc, low=0.0, high=1.0)
ylims!(ax_mcc, low=0.0, high=1.0)
xlims!(ax_tss, low=0.0, high=1.0)
ylims!(ax_tss, low=0.0, high=1.0)

ax_roc = Axis(fig[1,2], xlabel="False Positive Rate", ylabel="True Positive Rate")
ax_pr = Axis(fig[2,2], xlabel="False Positive Rate", ylabel="True Positive Rate")

for i in axes(T, 1)
    scatter!(ax_roc, fpr.(T[i,:]), tpr.(T[i,:]), color=:grey, markersize=2)
    scatter!(ax_pr, tpr.(T[i,:]), ppv.(T[i,:]), color=:grey, markersize=2)
end

arrows!(ax_roc, [0.5], [0.5], [-0.2], [0.2], color=:blue, linewidth=4)
arrows!(ax_roc, [0.5], [0.5], [0.2], [-0.2], color=:red, linewidth=2, linestyle=:dash)

lines!(ax_roc, [0.0, 1.0], [0.0, 1.0], color=:black, linestyle=:dash)
lines!(ax_pr, [0.0, 1.0], [0.5, 0.5], color=:black, linestyle=:dash)

arrows!(ax_pr, [0.5], [0.5], [0.2], [0.2], color=:blue, linewidth=4)
arrows!(ax_pr, [0.5], [0.5], [-0.2], [-0.2], color=:red, linewidth=2, linestyle=:dash)

xlims!(ax_roc, low=0.0, high=1.0)
ylims!(ax_roc, low=0.0, high=1.0)
xlims!(ax_pr, low=0.0, high=1.0)
ylims!(ax_pr, low=0.0, high=1.0)

current_figure()
```

## Tuned model with selected variables

```{julia}
#| echo: true
#| output: false
N_v2 = crossvalidate(naivebayes, ty, tX[:,available_variables], folds, thr[m])
```

## Measures on the confusion matrix {.smaller}

|     | BioClim | NBC  | BioClim (v.s.) | NBC (v.s.)  | NBC (v.s. + tuning)  |
|-----|----|-----------|----|-----------|----|
| FPR | `{julia} sm(fpr, B_v0)` | `{julia} sm(fpr, N_v0)` | `{julia} sm(fpr, B_v1)` | `{julia} sm(fpr, N_v1)` | `{julia} sm(fpr, N_v2)` |
| FNR | `{julia} sm(fnr, B_v0)` | `{julia} sm(fnr, N_v0)` | `{julia} sm(fnr, B_v1)` | `{julia} sm(fnr, N_v1)` | `{julia} sm(fnr, N_v2)` |
| TPR | `{julia} sm(tpr, B_v0)` | `{julia} sm(tpr, N_v0)` | `{julia} sm(tpr, B_v1)` | `{julia} sm(tpr, N_v1)` | `{julia} sm(tpr, N_v2)` |
| TNR | `{julia} sm(tnr, B_v0)` | `{julia} sm(tnr, N_v0)` | `{julia} sm(tnr, B_v1)` | `{julia} sm(tnr, N_v1)` | `{julia} sm(tnr, N_v2)` |
| TSS | `{julia} sm(trueskill, B_v0)` | `{julia} sm(trueskill, N_v0)` | `{julia} sm(trueskill, B_v1)` | `{julia} sm(trueskill, N_v1)` | `{julia} sm(trueskill, N_v2)` |
| MCC | `{julia} sm(mcc, B_v0)` | `{julia} sm(mcc, N_v0)` | `{julia} sm(mcc, B_v1)` | `{julia} sm(mcc, N_v1)` | `{julia} sm(mcc, N_v2)` |

## Tuned model performance

We can retrain over *all* the training data

```{julia}
#| echo: true
#| output: false
finalmodel = naivebayes(ty, tX[:,available_variables])
prediction = vec(mapslices(finalmodel, X[tidx,available_variables]; dims=2))
C = ConfusionMatrix(prediction, y[tidx], thr[m])
```

## Estimated performance

|     | Final model                        |
|-----|------------------------------------|
| FPR | `{julia} sm(fpr, C)` |
| FNR | `{julia} sm(fnr, C)` |
| TPR | `{julia} sm(tpr, C)` |
| TNR | `{julia} sm(tnr, C)` |
| MCC | `{julia} sm(trueskill, C)` |
| MCC | `{julia} sm(mcc, C)` |

## Acceptable bias

-   false positives: we expect that our knowledge of the distribution is incomplete!

-   false negatives: we used a heuristic for background points!

## Prediction for each pixel

```{julia}
#| echo: false
#| eval: true
#| output: false
function iqr(x)
    if all(isnan.(x))
        return 0.0
    else
        return first(diff(quantile(filter(!isnan, x), [0.25, 0.75])))
    end
end
samplemodels = [naivebayes(ty, tX[b,available_variables]) for b in bootstrap(ty, tX)]
variability = similar(first(predictors), Float64)
Threads.@threads for k in keys(variability)
    bootstraps = [samplemodel([p[k] for p in predictors[available_variables]]) for samplemodel in samplemodels]
    variability[k] = iqr(bootstraps)
end
```

```{julia}
#| echo: true
#| output: false
prediction = similar(first(predictors), Float64)
Threads.@threads for k in keys(prediction)
    prediction[k] = finalmodel([p[k] for p in predictors[available_variables]])
    if isnan(prediction[k])
        prediction[k] = 0.0
    end
end
```

## Tuned model - prediction

```{julia}
#| echo: false
#| output: true
fig = Figure(; resolution=(900, 500))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, prediction, colormap=cgrad(iridescent), colorrange=(0., 1.))
#heatmap!(ax, presence_layer; colormap=[:black,:black])
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

## Tuned model - uncertainty

```{julia}
#| echo: false
#| output: true
fig = Figure(; resolution=(900, 500))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, variability, colormap=cgrad(iridescent), colorrange=extrema(variability))
#heatmap!(ax, presence_layer; colormap=[:black,:black])
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

::: footer
IQR for the models trained on each fold
:::

## Tuned model - entropy

```{julia}
#| echo: false
#| output: true
function entropy(f)
    p = [f, 1-f]
    if minimum(p) == 0.0
        return 0.0
    end
    return -sum(p .* log2.(p))
end

fig = Figure(; resolution=(900, 500))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, entropy.(prediction), colormap=cgrad(iridescent), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

::: footer
Entropy (in bits) of the NBC probability
:::

## Tuned model - range

```{julia}
#| echo: false
#| output: true
fig = Figure(; resolution=(900, 500))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(prediction .>= thr[m]; colormap = cgrad([:lightgrey, :black]; alpha = 0.3))
heatmap!(ax, presence_layer; colormap=[:black,:black])
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

::: footer
Probability \> `{julia} round(thr[m]; digits=3)`
:::

## Predicting the predictions?

Shapley values (Monte-Carlo approximation): if we mix the variables across two observations, how important is the $i$-th variable?

Expresses "importance" as an additive factor on top of the *average* prediction (here: average prob. of occurrence)

```{julia}
#| echo: true
#| output: false
shapval = [similar(first(predictors), Float64) for i in eachindex(available_variables)]
Threads.@threads for k in keys(shapval[1])
    x = [p[k] for p in predictors[available_variables]]
    for i in axes(shapval, 1)
        shapval[i][k] = shapleyvalues(finalmodel, tX[:,available_variables], x, i; M=50)
        if isnan(shapval[i][k])
            shapval[i][k] = 0.0
        end
    end
end
```

## Importance of variables

```{julia}
#| echo: true
varimp = sum.(map(abs, shapval))
varimp ./= sum(varimp)
for v in sortperm(varimp, rev=true)
    vname = variables[available_variables[v]][2]
    vctr = round(Int, varimp[v]*100)
    println("$(vname) - $(vctr)%")
end
```

There is a difference between **contributing to model performance** and **contributing to model explainability**

## Top three variables

```{julia}
#| echo: false
#| output: true
fig = Figure(; resolution=(1500, 900))

totalvar = sum(map(abs, shapval))

gl = fig[1,1] = GridLayout()

fpos = 1
for i in sortperm(varimp; rev=true)[1:3]
    ax_mp = Axis(gl[fpos,1], aspect=DataAspect()) # Absolute contribution
    scl = maximum(abs.(extrema(shapval[i]))).*(-1,1)
    heatmap!(ax_mp, shapval[i], colorrange=scl, colormap=cgrad(nightfall), aspect=DataAspect())
    hidexdecorations!(ax_mp)
    hideydecorations!(ax_mp)

    ax_pp = Axis(gl[fpos,2], aspect=DataAspect()) # Relative contribution
    relcon = abs(shapval[i])/totalvar
    heatmap!(ax_pp, relcon, colorrange=(0, 1), colormap=cgrad(iridescent), aspect=DataAspect())
    hidexdecorations!(ax_pp)
    hideydecorations!(ax_pp)

    ax_pr = Axis(gl[fpos,3], title=variables[available_variables[i]][2]) # Partial response
    ylims!(ax_pr, scl)
    hexbin!(ax_pr, predictors[available_variables[i]], shapval[i], bins=200, colormap=cgrad(sunset))
    fpos += 1
end

current_figure()
```

## Most determinant predictor

```{julia}
shapmax = mosaic(argmax, map(abs, shapval[sortperm(varimp; rev=true)]))
for k in keys(shapmax)
    if shapmax[k] > 3
        shapmax[k] = 4
    end
end
pal = cgrad([colorant"#ddaa33", colorant"#bb5566", colorant"#004488", colorant"#000000"], 4, categorical=true)
fig = Figure(; resolution=(900, 500))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, shapmax, colormap=pal)
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

## Take-home

-   building a model is *incremental*

-   each step adds arbitrary decisions we can control for, justify, or live with

-   we can provide explanations for every single prediction

-   free online textbook (in development) at `https://tpoisot.github.io/DataSciForBiodivSci/`

## References